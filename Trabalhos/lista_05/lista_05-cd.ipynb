{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe7d217",
   "metadata": {},
   "source": [
    "# Exerc√≠cio: Regress√£o\n",
    "Objetivos: Exercitar os conceitos referente √† regress√£o.\n",
    "\n",
    "1. Crie um arquivo Jupyter Notebook e realize as seguintes opera√ß√µes:\n",
    "\n",
    "### a. Ler o dataset fakeTelegram.BR_2022.csv\n",
    "\n",
    "### b. Remova os trava-zaps, as linhas repetidas (duplicadas) e textos com menos de 5 palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541cda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect()\n",
    "\n",
    "telegram_data = conn.read_csv(\"../data/fakeTelegram.BR_2022.csv\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM telegram_data\n",
    "\"\"\"\n",
    "\n",
    "df = conn.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc4d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_message</th>\n",
       "      <th>id_member_anonymous</th>\n",
       "      <th>id_group_anonymous</th>\n",
       "      <th>media</th>\n",
       "      <th>media_type</th>\n",
       "      <th>media_url</th>\n",
       "      <th>has_media</th>\n",
       "      <th>has_media_url</th>\n",
       "      <th>trava_zap</th>\n",
       "      <th>text_content_anonymous</th>\n",
       "      <th>dataset_info_id</th>\n",
       "      <th>date_system</th>\n",
       "      <th>score_sentiment</th>\n",
       "      <th>score_misinformation</th>\n",
       "      <th>id_message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>messenger</th>\n",
       "      <th>media_name</th>\n",
       "      <th>media_md5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-05 06:25:04</td>\n",
       "      <td>1078cc958f0febe28f4d03207660715f</td>\n",
       "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ent√£o √© Fato Renato o √°udio que eu ouvi no wha...</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-05 06:25:28.863641</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16385</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-05 06:25:08</td>\n",
       "      <td>None</td>\n",
       "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Saiu no YouTube do presidente a 8 horas atr√°s,...</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-05 06:25:28.926311</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16386</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-05 06:26:28</td>\n",
       "      <td>92a2d8fd7144074f659d1d29dc3751da</td>\n",
       "      <td>9f2d7394334eb224c061c9740b5748fc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>√â isso, nossa parte j√° foi quase toda feita. N...</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-05 06:26:29.361949</td>\n",
       "      <td>-0.3551</td>\n",
       "      <td>0.157242</td>\n",
       "      <td>16366</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-05 06:27:28</td>\n",
       "      <td>d60aa38f62b4977426b70944af4aff72</td>\n",
       "      <td>c8f2de56550ed0bf85249608b7ead93d</td>\n",
       "      <td>94dca4cda503100ebfda7ce2bcc060eb.jpg</td>\n",
       "      <td>image/jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GENTE ACHEI ELES EM UMA SEITA MA√áON√ÅRICA</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-05 06:27:29.935624</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19281</td>\n",
       "      <td>Imagem</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>94dca4cda503100ebfda7ce2bcc060eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-05 06:27:44</td>\n",
       "      <td>cd6979b0b5265f08468fa1689b6300ce</td>\n",
       "      <td>e56ec342fc599ebb4ed89655eb6f03aa</td>\n",
       "      <td>5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg</td>\n",
       "      <td>image/jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-10-05 06:28:29.316325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>507185</td>\n",
       "      <td>Imagem</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>5ad5c8bbe9da93a37fecf3e5aa5b0637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_message               id_member_anonymous  \\\n",
       "0 2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
       "1 2022-10-05 06:25:08                              None   \n",
       "2 2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
       "3 2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
       "4 2022-10-05 06:27:44  cd6979b0b5265f08468fa1689b6300ce   \n",
       "\n",
       "                 id_group_anonymous                                 media  \\\n",
       "0  12283e08a2eb5789201e105b34489ee7                                  None   \n",
       "1  12283e08a2eb5789201e105b34489ee7                                  None   \n",
       "2  9f2d7394334eb224c061c9740b5748fc                                  None   \n",
       "3  c8f2de56550ed0bf85249608b7ead93d  94dca4cda503100ebfda7ce2bcc060eb.jpg   \n",
       "4  e56ec342fc599ebb4ed89655eb6f03aa  5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg   \n",
       "\n",
       "  media_type media_url  has_media  has_media_url  trava_zap  \\\n",
       "0       None      None      False          False      False   \n",
       "1       None      None      False          False      False   \n",
       "2       None      None      False          False      False   \n",
       "3  image/jpg      None       True          False      False   \n",
       "4  image/jpg      None       True          False      False   \n",
       "\n",
       "                              text_content_anonymous  dataset_info_id  \\\n",
       "0  Ent√£o √© Fato Renato o √°udio que eu ouvi no wha...                5   \n",
       "1  Saiu no YouTube do presidente a 8 horas atr√°s,...                5   \n",
       "2  √â isso, nossa parte j√° foi quase toda feita. N...                5   \n",
       "3           GENTE ACHEI ELES EM UMA SEITA MA√áON√ÅRICA                5   \n",
       "4                                               None                5   \n",
       "\n",
       "                 date_system  score_sentiment  score_misinformation  \\\n",
       "0 2022-10-05 06:25:28.863641           0.0000                   NaN   \n",
       "1 2022-10-05 06:25:28.926311           0.0644                   NaN   \n",
       "2 2022-10-05 06:26:29.361949          -0.3551              0.157242   \n",
       "3 2022-10-05 06:27:29.935624           0.0000                   NaN   \n",
       "4 2022-10-05 06:28:29.316325              NaN                   NaN   \n",
       "\n",
       "   id_message message_type messenger media_name  \\\n",
       "0       16385        Texto  telegram       None   \n",
       "1       16386        Texto  telegram       None   \n",
       "2       16366        Texto  telegram       None   \n",
       "3       19281       Imagem  telegram       None   \n",
       "4      507185       Imagem  telegram       None   \n",
       "\n",
       "                          media_md5  \n",
       "0                              None  \n",
       "1                              None  \n",
       "2                              None  \n",
       "3  94dca4cda503100ebfda7ce2bcc060eb  \n",
       "4  5ad5c8bbe9da93a37fecf3e5aa5b0637  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca3ab12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557586, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd08a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conn.execute(f\"\"\"\n",
    "    SELECT * \n",
    "    FROM telegram_data\n",
    "    WHERE trava_zap IS NOT TRUE\n",
    "\"\"\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f88e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557570, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84fd9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = conn.execute(\"SELECT DISTINCT * FROM df\").fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1186c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336944, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM df_\n",
    "WHERE array_length(string_split(text_content_anonymous, ' ')) >= 5\n",
    "\"\"\"\n",
    "\n",
    "df = conn.execute(query).fetch_df()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ada34",
   "metadata": {},
   "source": [
    "### c. Agrupe as linhas com postagens iguais ou extremamente semelhantes. Aqui voc√™ pode utilizar uma m√©trica de semelhan√ßa de textos. Crie uma vari√°vel para representar a quantidade de vezes que a mensagem foi compartilhada. Observe que ao agrupar linhas que possuem a ‚Äúmesma‚Äù postagem (texto), voc√™ deve escolher como valor para as vari√°veis data e hora da postagem, os valores da c√≥pia mais antiga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # remover acentos\n",
    "    text = unicodedata.normalize('NFKD', text)\\\n",
    "           .encode('ascii', 'ignore')\\\n",
    "           .decode('utf-8')\n",
    "    \n",
    "    # remover pontua√ß√£o e caracteres especiais\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # remover emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # s√≠mbolos & pictogramas\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transporte & s√≠mbolos\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # bandeiras (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9616063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text_content_anonymous'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2f7c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasketch in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (1.6.5)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (from datasketch) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (from datasketch) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b09bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "import pandas as pd\n",
    "\n",
    "texts = df['cleaned_text'].tolist()\n",
    "\n",
    "minhashes = {}\n",
    "for idx, text in enumerate(texts):\n",
    "    mh = MinHash(num_perm=128)\n",
    "    for word in text.split():\n",
    "        mh.update(word.encode('utf-8'))\n",
    "    minhashes[idx] = mh\n",
    "\n",
    "\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "\n",
    "for idx, mh in minhashes.items():\n",
    "    lsh.insert(idx, mh)\n",
    "\n",
    "groups = []\n",
    "used = set()\n",
    "\n",
    "for idx in minhashes:\n",
    "    if idx not in used:\n",
    "        similar_indices = lsh.query(minhashes[idx])\n",
    "        \n",
    "        groups.append(similar_indices)\n",
    "        used.update(similar_indices)\n",
    "\n",
    "grouped_data = []\n",
    "for group in groups:\n",
    "    group_df = df.iloc[list(group)]\n",
    "    oldest = group_df.loc[group_df['date_message'].idxmin()]\n",
    "    \n",
    "    count = len(group_df)\n",
    "    \n",
    "    new_row = oldest.to_dict()\n",
    "    new_row['shared_count'] = count\n",
    "    grouped_data.append(new_row)\n",
    "\n",
    "result_df = pd.DataFrame(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4534c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_message</th>\n",
       "      <th>id_member_anonymous</th>\n",
       "      <th>id_group_anonymous</th>\n",
       "      <th>media</th>\n",
       "      <th>media_type</th>\n",
       "      <th>media_url</th>\n",
       "      <th>has_media</th>\n",
       "      <th>has_media_url</th>\n",
       "      <th>trava_zap</th>\n",
       "      <th>text_content_anonymous</th>\n",
       "      <th>...</th>\n",
       "      <th>date_system</th>\n",
       "      <th>score_sentiment</th>\n",
       "      <th>score_misinformation</th>\n",
       "      <th>id_message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>messenger</th>\n",
       "      <th>media_name</th>\n",
       "      <th>media_md5</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>shared_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>2022-09-29 00:00:04</td>\n",
       "      <td>f0ac73b52a8c343778e3d68682d6f529</td>\n",
       "      <td>857cd5311da1bdc15eb9e6918a47c6c6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bitcoin has really changed my life for the bes...</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-10-03 04:04:31.751964</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.101220</td>\n",
       "      <td>873367</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>bitcoin has really changed my life for the bes...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>2022-09-29 00:00:07</td>\n",
       "      <td>3b94e832cae91837c425363cd63fdfb0</td>\n",
       "      <td>959f13e0079883060632c74ffc81c547</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>√©, mas o circo t√° armado pra fazer aquele espe...</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-10-03 04:04:31.881104</td>\n",
       "      <td>-0.8885</td>\n",
       "      <td>0.271192</td>\n",
       "      <td>9290</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>e mas o circo ta armado pra fazer aquele espet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82790</th>\n",
       "      <td>2022-09-29 00:00:11</td>\n",
       "      <td>None</td>\n",
       "      <td>2ff252ad4422e11a6a8abfaa747abb55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t.me/alexeconomia</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>BOE TOMOU MEDIDAS DE EMERG√äNCIA NA QUARTA-FEIR...</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-10-03 04:04:32.024363</td>\n",
       "      <td>-0.7269</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>47690</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>boe tomou medidas de emergencia na quartafeira...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12253</th>\n",
       "      <td>2022-09-29 00:00:13</td>\n",
       "      <td>61606aac57503ba74c73c757039b460b</td>\n",
       "      <td>b11f2df64ac19aad47a50accf32052d6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Caramba! Por isso o meu n√£o compartilha nem to...</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-10-03 04:04:32.128902</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151069</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>caramba por isso o meu nao compartilha nem tod...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9831</th>\n",
       "      <td>2022-09-29 00:00:15</td>\n",
       "      <td>abe534d581ec6d552243d6955d3c3cd8</td>\n",
       "      <td>92bb16424091252ba82616cde38e1c19</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Welcome, Suely Pimentel\\n\\nüî∏ [USER] ‚Äî professi...</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-10-03 04:04:32.233217</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39817</td>\n",
       "      <td>Texto</td>\n",
       "      <td>telegram</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>welcome suely pimentel user professional tool ...</td>\n",
       "      <td>4618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_message               id_member_anonymous  \\\n",
       "9354  2022-09-29 00:00:04  f0ac73b52a8c343778e3d68682d6f529   \n",
       "12252 2022-09-29 00:00:07  3b94e832cae91837c425363cd63fdfb0   \n",
       "82790 2022-09-29 00:00:11                              None   \n",
       "12253 2022-09-29 00:00:13  61606aac57503ba74c73c757039b460b   \n",
       "9831  2022-09-29 00:00:15  abe534d581ec6d552243d6955d3c3cd8   \n",
       "\n",
       "                     id_group_anonymous media media_type          media_url  \\\n",
       "9354   857cd5311da1bdc15eb9e6918a47c6c6  None       None               None   \n",
       "12252  959f13e0079883060632c74ffc81c547  None       None               None   \n",
       "82790  2ff252ad4422e11a6a8abfaa747abb55  None       None  t.me/alexeconomia   \n",
       "12253  b11f2df64ac19aad47a50accf32052d6  None       None               None   \n",
       "9831   92bb16424091252ba82616cde38e1c19  None       None               None   \n",
       "\n",
       "       has_media  has_media_url  trava_zap  \\\n",
       "9354       False          False      False   \n",
       "12252      False          False      False   \n",
       "82790      False           True      False   \n",
       "12253      False          False      False   \n",
       "9831       False          False      False   \n",
       "\n",
       "                                  text_content_anonymous  ...  \\\n",
       "9354   Bitcoin has really changed my life for the bes...  ...   \n",
       "12252  √©, mas o circo t√° armado pra fazer aquele espe...  ...   \n",
       "82790  BOE TOMOU MEDIDAS DE EMERG√äNCIA NA QUARTA-FEIR...  ...   \n",
       "12253  Caramba! Por isso o meu n√£o compartilha nem to...  ...   \n",
       "9831   Welcome, Suely Pimentel\\n\\nüî∏ [USER] ‚Äî professi...  ...   \n",
       "\n",
       "                     date_system score_sentiment  score_misinformation  \\\n",
       "9354  2022-10-03 04:04:31.751964          0.0000              0.101220   \n",
       "12252 2022-10-03 04:04:31.881104         -0.8885              0.271192   \n",
       "82790 2022-10-03 04:04:32.024363         -0.7269              0.065431   \n",
       "12253 2022-10-03 04:04:32.128902          0.0000                   NaN   \n",
       "9831  2022-10-03 04:04:32.233217          0.0000                   NaN   \n",
       "\n",
       "       id_message  message_type messenger media_name media_md5  \\\n",
       "9354       873367         Texto  telegram       None      None   \n",
       "12252        9290         Texto  telegram       None      None   \n",
       "82790       47690         Texto  telegram       None      None   \n",
       "12253      151069         Texto  telegram       None      None   \n",
       "9831        39817         Texto  telegram       None      None   \n",
       "\n",
       "                                            cleaned_text shared_count  \n",
       "9354   bitcoin has really changed my life for the bes...            2  \n",
       "12252  e mas o circo ta armado pra fazer aquele espet...            1  \n",
       "82790  boe tomou medidas de emergencia na quartafeira...            1  \n",
       "12253  caramba por isso o meu nao compartilha nem tod...            2  \n",
       "9831   welcome suely pimentel user professional tool ...         4618  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df.sort_values('date_message')\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d71651",
   "metadata": {},
   "source": [
    "### d. Voc√™ pode criar novos atributos num√©ricos, tais como: quantidade de palavras, quantidade de caracteres etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb1404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            cleaned_text  shared_count  \\\n",
      "9354   bitcoin has really changed my life for the bes...             2   \n",
      "12252  e mas o circo ta armado pra fazer aquele espet...             1   \n",
      "82790  boe tomou medidas de emergencia na quartafeira...             1   \n",
      "12253  caramba por isso o meu nao compartilha nem tod...             2   \n",
      "9831   welcome suely pimentel user professional tool ...          4618   \n",
      "\n",
      "       word_count  char_count  unique_word_ratio  link_count  avg_word_length  \n",
      "9354         72.0       366.0           0.666667         0.0         4.097222  \n",
      "12252        28.0       142.0           0.857143         0.0         4.107143  \n",
      "82790        34.0       207.0           0.882353         0.0         5.117647  \n",
      "12253        19.0       102.0           0.947368         0.0         4.421053  \n",
      "9831         10.0        74.0           1.000000         0.0         6.500000  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_features(text):\n",
    "    if not isinstance(text, str):\n",
    "        return {\n",
    "            'word_count': 0,\n",
    "            'char_count': 0,\n",
    "            'unique_word_ratio': 0,\n",
    "            'link_count': 0,\n",
    "            'avg_word_length': 0\n",
    "        }\n",
    "    \n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    char_count = len(text)\n",
    "    \n",
    "    unique_words = set(words)\n",
    "    unique_word_ratio = len(unique_words) / word_count if word_count > 0 else 0\n",
    "    \n",
    "    link_count = len(re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text))\n",
    "    \n",
    "    avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'word_count': word_count,\n",
    "        'char_count': char_count,\n",
    "        'unique_word_ratio': unique_word_ratio,\n",
    "        'link_count': link_count,\n",
    "        'avg_word_length': avg_word_length\n",
    "    }\n",
    "\n",
    "features = result_df['cleaned_text'].apply(lambda x: pd.Series(extract_features(x)))\n",
    "\n",
    "result_df = pd.concat([result_df, features], axis=1)\n",
    "\n",
    "print(result_df[['cleaned_text', 'shared_count', 'word_count', 'char_count', \n",
    "                'unique_word_ratio', 'link_count', 'avg_word_length']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8fd348",
   "metadata": {},
   "source": [
    "# Utilizando os dados referente a postagens no Telegram, crie um modelo preditivo (regressor) para, dado os dados de uma postagem, prever a quantidade de compartilhamentos dessa mensagem, o que √© denominado potencial de ‚Äúviraliza√ß√£o‚Äù."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f41337",
   "metadata": {},
   "source": [
    "## A avalia√ß√£o experimental dever√° considerar:\n",
    "\n",
    "e. O modelo de regress√£o: regress√£o linear multivariada, regress√£o polinomial\n",
    "multivariada;\n",
    "\n",
    "f. Explorar fun√ß√µes: exponencial, seno, cosseno (OPCIONAL);\n",
    "\n",
    "g. Regulariza√ß√£o: Com regulariza√ß√£o (Ridge, Lasso ou ElasticNet) e sem\n",
    "regulariza√ß√£o;\n",
    "\n",
    "h. Normaliza√ß√£o dos dados: sem normaliza√ß√£o, Z-Score, Min-Max (OPCIONAL);\n",
    "\n",
    "i. Pr√©-processamento de dados: sem pr√©-processamento e com pr√©-processamento;\n",
    "\n",
    "j. Embedding: BOW, TF-IDF, Word2Vec;\n",
    "\n",
    "k. N-Gramas: unigramas, bigramas, trigramas;\n",
    "\n",
    "l. Treinamento, Valida√ß√£o e Teste: Outer K-Fold Cross-Validation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b33d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features = ['word_count', 'char_count', 'unique_word_ratio', \n",
    "                   'link_count', 'avg_word_length']\n",
    "\n",
    "X = result_df[numeric_features]\n",
    "y = np.log1p(result_df['shared_count'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251729db",
   "metadata": {},
   "source": [
    "### item e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6273034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.3789330706422574\n",
      "Polynomial Regression MSE: 0.37830116960476035\n"
     ]
    }
   ],
   "source": [
    "lr_model = Pipeline([\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Linear Regression MSE:\", mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "poly_model = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "poly_model.fit(X_train, y_train)\n",
    "y_pred_poly = poly_model.predict(X_test)\n",
    "print(\"Polynomial Regression MSE:\", mean_squared_error(y_test, y_pred_poly))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de3357",
   "metadata": {},
   "source": [
    "### item f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376a06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a23725a1",
   "metadata": {},
   "source": [
    "### item g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeaf69c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MSE: 0.3789332050551602\n",
      "Lasso MSE: 0.3799010009679673\n",
      "ElasticNet MSE: 0.37977058145294446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge = Ridge(alpha=1.0).fit(X_train, y_train)\n",
    "lasso = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "elastic = ElasticNet(alpha=0.1, l1_ratio=0.5).fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge MSE:\", mean_squared_error(y_test, ridge.predict(X_test)))\n",
    "print(\"Lasso MSE:\", mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "print(\"ElasticNet MSE:\", mean_squared_error(y_test, elastic.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a21562",
   "metadata": {},
   "source": [
    "### Item h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeca5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM_NORMALIZACAO -> MSE: 0.3789, R¬≤: 0.0033\n",
      "ZSCORE -> MSE: 0.3789, R¬≤: 0.0033\n",
      "MINMAX -> MSE: 0.3789, R¬≤: 0.0033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "results = {}\n",
    "\n",
    "pipeline_none = Pipeline([\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "pipeline_none.fit(X_train, y_train)\n",
    "y_pred_none = pipeline_none.predict(X_test)\n",
    "results['sem_normalizacao'] = {\n",
    "    'MSE': mean_squared_error(y_test, y_pred_none),\n",
    "    'R2': r2_score(y_test, y_pred_none)\n",
    "}\n",
    "\n",
    "pipeline_zscore = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "pipeline_zscore.fit(X_train, y_train)\n",
    "y_pred_zscore = pipeline_zscore.predict(X_test)\n",
    "results['zscore'] = {\n",
    "    'MSE': mean_squared_error(y_test, y_pred_zscore),\n",
    "    'R2': r2_score(y_test, y_pred_zscore)\n",
    "}\n",
    "\n",
    "pipeline_minmax = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "pipeline_minmax.fit(X_train, y_train)\n",
    "y_pred_minmax = pipeline_minmax.predict(X_test)\n",
    "results['minmax'] = {\n",
    "    'MSE': mean_squared_error(y_test, y_pred_minmax),\n",
    "    'R2': r2_score(y_test, y_pred_minmax)\n",
    "}\n",
    "\n",
    "for key, metrics in results.items():\n",
    "    print(f\"{key.upper()} -> MSE: {metrics['MSE']:.4f}, R¬≤: {metrics['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f08f1",
   "metadata": {},
   "source": [
    "### item i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d20683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM PR√â-PROCESSAMENTO\n",
      "MSE: 0.3789, R¬≤: 0.0033\n",
      "\n",
      "COM PR√â-PROCESSAMENTO (Remo√ß√£o de outliers + Z-Score)\n",
      "MSE: 0.3604, R¬≤: 0.0028\n"
     ]
    }
   ],
   "source": [
    "pipeline_sem_preproc = Pipeline([\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "pipeline_sem_preproc.fit(X_train, y_train)\n",
    "y_pred1 = pipeline_sem_preproc.predict(X_test)\n",
    "mse1 = mean_squared_error(y_test, y_pred1)\n",
    "r2_1 = r2_score(y_test, y_pred1)\n",
    "\n",
    "def remove_outliers_iqr(X, y, features):\n",
    "    X_clean = X.copy()\n",
    "    y_clean = y.copy()\n",
    "    for col in features:\n",
    "        Q1 = X_clean[col].quantile(0.25)\n",
    "        Q3 = X_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        mask = (X_clean[col] >= (Q1 - 1.5 * IQR)) & (X_clean[col] <= (Q3 + 1.5 * IQR))\n",
    "        X_clean = X_clean[mask]\n",
    "        y_clean = y_clean[mask]\n",
    "    return X_clean, y_clean\n",
    "\n",
    "X_clean, y_clean = remove_outliers_iqr(X, y, numeric_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline_preproc = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "pipeline_preproc.fit(X_train, y_train)\n",
    "y_pred = pipeline_preproc.predict(X_test)\n",
    "\n",
    "mse2 = mean_squared_error(y_test, y_pred)\n",
    "r2_2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"SEM PR√â-PROCESSAMENTO\")\n",
    "print(f\"MSE: {mse1:.4f}, R¬≤: {r2_1:.4f}\")\n",
    "\n",
    "print(\"\\nCOM PR√â-PROCESSAMENTO (Remo√ß√£o de outliers + Z-Score)\")\n",
    "print(f\"MSE: {mse2:.4f}, R¬≤: {r2_2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566a789",
   "metadata": {},
   "source": [
    "### j. Embedding: BOW, TF-IDF, Word2Vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e396b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words:\n",
      "MSE: 4.0265, R¬≤: -9.5910\n",
      "\n",
      "TF-IDF:\n",
      "MSE: 1.5508, R¬≤: -3.0792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "text_feature = 'cleaned_text'\n",
    "numeric_features = ['word_count', 'char_count', 'unique_word_ratio', \n",
    "                    'link_count', 'avg_word_length']\n",
    "X = result_df[[text_feature] + numeric_features]\n",
    "y = np.log1p(result_df['shared_count'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bow_transformer = ColumnTransformer(transformers=[\n",
    "    ('text', CountVectorizer(), text_feature),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "bow_pipeline = Pipeline([\n",
    "    ('preproc', bow_transformer),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "bow_pipeline.fit(X_train, y_train)\n",
    "y_pred_bow = bow_pipeline.predict(X_test)\n",
    "\n",
    "tfidf_transformer = ColumnTransformer(transformers=[\n",
    "    ('text', TfidfVectorizer(), text_feature),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('preproc', tfidf_transformer),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "y_pred_tfidf = tfidf_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Bag of Words:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_bow):.4f}, R¬≤: {r2_score(y_test, y_pred_bow):.4f}\")\n",
    "\n",
    "print(\"\\nTF-IDF:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_tfidf):.4f}, R¬≤: {r2_score(y_test, y_pred_tfidf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c51c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (from gensim) (1.26.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\pedro\\miniforge3\\envs\\cd\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a20fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec embedding:\n",
      "MSE: 0.3588, R¬≤: 0.0564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "w2v_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, w2v_model):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.dim = w2v_model.vector_size\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self._average_word_vectors(doc) for doc in X])\n",
    "    \n",
    "    def _average_word_vectors(self, doc):\n",
    "        words = str(doc).split()\n",
    "        vectors = [self.w2v_model[word] for word in words if word in self.w2v_model]\n",
    "        if not vectors:\n",
    "            return np.zeros(self.dim)\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "w2v_vectorizer = Word2VecVectorizer(w2v_model=w2v_model)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('w2v', w2v_vectorizer, text_feature),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline_w2v = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline_w2v.fit(X_train, y_train)\n",
    "y_pred_w2v = pipeline_w2v.predict(X_test)\n",
    "\n",
    "print(\"Word2Vec embedding:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_w2v):.4f}, R¬≤: {r2_score(y_test, y_pred_w2v):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69767f",
   "metadata": {},
   "source": [
    "### k. N-Gramas: unigramas, bigramas, trigramas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34984891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_pipeline(ngram_range):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('vec', vectorizer, text_feature),\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8cb2d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: Unigrama\n",
      "MSE: 4.0265\n",
      "R¬≤: -9.5910\n",
      "\n",
      "Modelo: Bigrama\n",
      "MSE: 1.1192\n",
      "R¬≤: -1.9438\n",
      "\n",
      "Modelo: Trigrama\n",
      "MSE: 0.5491\n",
      "R¬≤: -0.4443\n"
     ]
    }
   ],
   "source": [
    "for name, ngram in [('Unigrama', (1, 1)), ('Bigrama', (2, 2)), ('Trigrama', (3, 3))]:\n",
    "    print(f'\\nModelo: {name}')\n",
    "    pipeline = build_ngram_pipeline(ngram)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'MSE: {mse:.4f}')\n",
    "    print(f'R¬≤: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ac1fd",
   "metadata": {},
   "source": [
    "### l. Treinamento, Valida√ß√£o e Teste: Outer K-Fold Cross-Validation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "no_scaler = 'passthrough'\n",
    "zscore = StandardScaler()\n",
    "\n",
    "bow = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "\n",
    "def build_preprocessor(embedder, scaler):\n",
    "    return ColumnTransformer([\n",
    "        ('text', embedder, text_feature),\n",
    "        ('num', scaler, numeric_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'preproc__text': [bow, tfidf],\n",
    "        'preproc__num': [no_scaler, zscore],\n",
    "        'regressor': [Ridge()],\n",
    "        'regressor__alpha': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d64bef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MSE=0.3212 | R¬≤=0.1550 | Best model: {'preproc__num': 'passthrough', 'preproc__text': TfidfVectorizer(), 'regressor': Ridge(), 'regressor__alpha': 10.0}\n",
      "Fold 2: MSE=0.3153 | R¬≤=0.1617 | Best model: {'preproc__num': 'passthrough', 'preproc__text': TfidfVectorizer(), 'regressor': Ridge(), 'regressor__alpha': 10.0}\n",
      "Fold 3: MSE=0.3247 | R¬≤=0.1686 | Best model: {'preproc__num': 'passthrough', 'preproc__text': TfidfVectorizer(), 'regressor': Ridge(), 'regressor__alpha': 10.0}\n",
      "Fold 4: MSE=0.3267 | R¬≤=0.1570 | Best model: {'preproc__num': 'passthrough', 'preproc__text': TfidfVectorizer(), 'regressor': Ridge(), 'regressor__alpha': 10.0}\n",
      "Fold 5: MSE=0.3280 | R¬≤=0.1587 | Best model: {'preproc__num': 'passthrough', 'preproc__text': TfidfVectorizer(), 'regressor': Ridge(), 'regressor__alpha': 10.0}\n",
      "\n",
      "==== Resultados finais ====\n",
      "MSE m√©dio: 0.3232\n",
      "R¬≤ m√©dio: 0.1602\n"
     ]
    }
   ],
   "source": [
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "outer_scores = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preproc', build_preprocessor(bow, no_scaler)),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Fold {i+1}: MSE={mse:.4f} | R¬≤={r2:.4f} | Best model: {grid.best_params_}\")\n",
    "    outer_scores.append((mse, r2, grid.best_params_))\n",
    "\n",
    "mse_scores = [score[0] for score in outer_scores]\n",
    "r2_scores = [score[1] for score in outer_scores]\n",
    "\n",
    "print(\"\\n==== Resultados finais ====\")\n",
    "print(f\"MSE m√©dio: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"R¬≤ m√©dio: {np.mean(r2_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865714a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
